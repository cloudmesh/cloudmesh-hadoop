version: "3.7"

services:
  hadoop-build:
    image: cloudmesh/docker-hadoop
    build: .
    #volumes:
    #  - ./config:/etc/hadoop/.
      
    stdin_open: true
    tty: true
    
  #namenode:
  #  image: cloudmesh/docker-hadoop-namenode
  #  build: ./namenode
  #  hostname: namenode
  #  container_name: namenode
  #  domainname: hadoop
  #  networks:
  #    - hbase
  #  volumes:
  #    - namenode-volume:/hadoop/dfs/name
  #  environment:
  #    - GANGLIA_HOST=localhost
  #    - CLUSTER_NAME=cloudmesh-hadoop
  #  env_file: ./hadoop.env
  #  depends_on:
  #    - hadoop-build
  
  namenode:
    image: cloudmesh/docker-hadoop-namenode
    #build: ./Hadoop/namenode/.
    build: ./namenode
    networks:
      - hbase
    volumes:
    #  - namenode:/hadoop/dfs/name
      - namenode-volume:/hadoop/dfs/name
    environment:
      - GANGLIA_HOST=localhost
      - CLUSTER_NAME=cloudmesh-hadoop
    env_file:
      - ./hadoop.env
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.hostname == akswnc4.aksw.uni-leipzig.de
      labels:
        traefik.docker.network: hbase
        traefik.port: 5007
    depends_on:
      - hadoop-build
    
      
  ping-namenode:
    image: ubuntu:18.04
    stdin_open: true
    tty: true
    networks:
      - hbase
    links:
      - namenode
    depends_on:
      - namenode

  datanode:
    image: cloudmesh/docker-hadoop-datanode
    build: ./datanode
    hostname: datanode1
    container_name: datanode1
    domainname: hadoop
    networks:
      - hbase
    volumes:
      - datanode-volume:/hadoop/dfs/data
    environment:
      - GANGLIA_HOST=localhost
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    env_file: ./hadoop.env
    depends_on:
      - hadoop-build
      - namenode

  resourcemanager:
    image: cloudmesh/docker-hadoop-resourcemanager
    build: ./resourcemanager
    hostname: resourcemanager
    container_name: resourcemanager
    domainname: hadoop
    networks:
      - hbase
    environment:
      - GANGLIA_HOST=<gmond-receiver-host>
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - YARN_CONF_yarn_log___aggregation___enable=true
    env_file: ./hadoop.env
    depends_on: 
      - hadoop-build
      - namenode

  nodemanager:
    image: cloudmesh/docker-hadoop-nodemanager
    build: ./nodemanager
    hostname: nodemanager1
    container_name: nodemanager1
    domainname: hadoop
    networks:
      - hbase
    environment:
      - GANGLIA_HOST=<gmond-receiver-host>
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
      - YARN_CONF_yarn_log___aggregation___enable=true
      - YARN_CONF_yarn_nodemanager_remote___app___log___dir=/app-logs
    env_file: ./hadoop.env
    depends_on: 
      - hadoop-build
      - namenode

networks:
  hbase:

volumes:
  namenode-volume:
  datanode-volume:
